{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11doBf4tVrAXv5cTl5xhvMap6qIcjEeFo","timestamp":1707753379453}],"gpuType":"T4","authorship_tag":"ABX9TyOiEQtqS4lEVvM9tE2Bfcsw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Dowloading the Pix3D dataset from their URL. Dataset will be stored in the this session's memory. The whole dowload should take about 2 minutes, depends on speed of internet connection."],"metadata":{"id":"0MOXFMtHaxmz"}},{"cell_type":"code","source":["!wget http://pix3d.csail.mit.edu/data/pix3d.zip\n","!unzip pix3d.zip && rm pix3d.zip"],"metadata":{"id":"oaGKIyuGGO8F","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Importing libraries necessary for data reload.\n","Data are in the dataset as .jpg or .png images, .txt key points list, .obj CAD model, .mtl model and .mat Matlab voxel model. All the information needed for reload are stored in pix3d.json file."],"metadata":{"id":"gr0ObWBBbVPe"}},{"cell_type":"code","source":["# scipy for .mat to numpy conversion,\n","# numpy for mathematical and array operations, PIL for images,\n","# Path for work with paths and json for .json file reading\n","import scipy\n","import numpy as np\n","import PIL\n","from PIL import Image\n","\n","from pathlib import Path\n","import json\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# Connection to google drive if needed\n","#from google.colab import drive\n","#drive.mount('/content/drive')"],"metadata":{"id":"mVivjIQMdUNo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Functions needed for creating a training set. Comments inside the cell."],"metadata":{"id":"sdKCEvSbdaRb"}},{"cell_type":"code","source":["# data that are downloaded durring session are store in /content\n","data_path = '/content/'\n","###\n","\n","# this function reads paths to images and voxel models from json file\n","def load_paths_from_json(json_file=\"pix3d.json\"):\n","    with open(data_path + json_file, \"r\") as f:\n","        config = json.loads(f.read())\n","\n","    img_paths = []\n","    voxel_paths = []\n","\n","    for p in config:\n","        img_paths.append(p['img'])\n","        voxel_paths.append(p['voxel'])\n","\n","    return img_paths, voxel_paths\n","\n","# converting .mat voxels to numpy array voxels\n","def voxel_mat2np(path):\n","    mat = scipy.io.loadmat(path)\n","    np_array = mat['voxel']\n","    return np_array\n","\n","# reshaping voxel model from 128x128x128 to 32x32x32\n","def reshape_vox(vox):\n","    vox = tf.expand_dims(vox, axis=-1)\n","    vox = tf.expand_dims(vox, axis=0)\n","    vox = vox.numpy().astype('float16')\n","    maxpool = layers.MaxPooling3D(pool_size=4)\n","    voxels_32 = maxpool(vox)\n","    voxels_32 = layers.Reshape((32, 32, 32))(voxels_32)\n","    voxels_32 = voxels_32.numpy().astype('uint8')\n","\n","    return voxels_32\n","\n","\n","# loading image-voxel pairs from paths to them\n","def load_img_voxel(img_path, voxel_path,path=data_path):\n","    img = Image.open(data_path + img_path)\n","    img = img.resize((256,256))\n","    array = np.array(img)\n","\n","    voxel = voxel_mat2np(data_path + voxel_path)\n","    voxel = reshape_vox(voxel)\n","\n","    if np.shape(array) == (256,256,3):\n","        return array, voxel"],"metadata":{"id":"6YrYrKMRdqbO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As this single Colab session couldn't hold all of the arrays loaded in RAM at once, for purpose of this code presentation only 1000 randomly selected image-voxel pairs will be loaded."],"metadata":{"id":"ppC2Jm-og0VE"}},{"cell_type":"code","source":["import random\n","#n = np.shape(images)[0]\n","n = 10069\n","random.seed(42)\n","indx = random.sample(range(n),1000)\n","print(indx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v9ECXDDNfm49","executionInfo":{"status":"ok","timestamp":1715869384523,"user_tz":-120,"elapsed":13,"user":{"displayName":"Matyáš Pokorný","userId":"06975905606393697570"}},"outputId":"8db527b8-40cb-4aea-c485-655687281211"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1824, 409, 4506, 4012, 3657, 2286, 1679, 8935, 1424, 9674, 6912, 520, 488, 1535, 3582, 3811, 8279, 9863, 434, 9195, 3257, 8928, 6873, 3611, 7359, 9654, 4557, 106, 2615, 6924, 5574, 4552, 2547, 3527, 5514, 1674, 1519, 6224, 1584, 5881, 5635, 9891, 4333, 711, 7527, 8785, 2045, 6201, 1291, 9044, 4803, 5925, 9459, 3150, 1139, 750, 3733, 4741, 1307, 3814, 1654, 6227, 4554, 7428, 5977, 2664, 6065, 5820, 3432, 4374, 1169, 9980, 2803, 8751, 4010, 2677, 7573, 6216, 4422, 9125, 3598, 5313, 916, 3752, 525, 5168, 6572, 4386, 1084, 3456, 9292, 5155, 3483, 8179, 6482, 7517, 2340, 4339, 2287, 4040, 9197, 8830, 4304, 9577, 7019, 9560, 6543, 5930, 3593, 2266, 8348, 8085, 1489, 771, 1796, 2504, 2621, 6916, 9771, 1040, 6304, 6252, 9763, 7668, 8669, 4119, 9064, 188, 1876, 8797, 4371, 5573, 1827, 4808, 7123, 2591, 7433, 53, 4315, 8201, 2927, 8317, 1743, 4889, 9977, 3258, 6126, 2646, 8837, 8689, 9, 9813, 5310, 8005, 319, 1832, 5947, 5038, 3923, 949, 3946, 9295, 1290, 1403, 7962, 1133, 8727, 2060, 2103, 7787, 9007, 2705, 4342, 8645, 9938, 6932, 3470, 8835, 3295, 5107, 6537, 6118, 7177, 8479, 7397, 1982, 4061, 3681, 1049, 5539, 344, 9638, 9075, 3770, 9641, 3608, 117, 1163, 964, 3750, 1104, 514, 5413, 1160, 8423, 3899, 4562, 7953, 3510, 8834, 2167, 9355, 9440, 7744, 3981, 7749, 6669, 3119, 1545, 1588, 7062, 5804, 6939, 6735, 7651, 887, 1612, 993, 6596, 5559, 1790, 4073, 3139, 3116, 8786, 7350, 2296, 3006, 4563, 7579, 4092, 1235, 7260, 9016, 1604, 828, 8856, 241, 1528, 3872, 2724, 6658, 7956, 7886, 3502, 6570, 960, 2697, 6209, 35, 6396, 4345, 7454, 4673, 6930, 9105, 7973, 2536, 3111, 4861, 3566, 958, 9489, 8883, 998, 5138, 936, 821, 9571, 7811, 8238, 8701, 2579, 931, 8320, 1312, 3044, 1122, 9749, 1113, 3853, 6615, 1964, 9333, 4033, 9485, 9740, 651, 1343, 6868, 9562, 9260, 8565, 5183, 4272, 3346, 5147, 3910, 4351, 6484, 2144, 4915, 7491, 5180, 1188, 152, 7508, 9224, 1638, 1200, 8808, 3492, 8288, 2170, 5718, 1127, 4002, 6054, 4669, 2584, 7179, 8900, 4956, 10021, 8666, 128, 9086, 4905, 1697, 2200, 1891, 1753, 2546, 4462, 4616, 9909, 3450, 5617, 3335, 4325, 8280, 8004, 4114, 832, 1512, 4533, 722, 58, 5464, 2143, 4291, 2647, 7239, 9038, 7007, 9189, 158, 1232, 2442, 8938, 590, 6049, 9543, 9052, 2426, 7041, 2088, 685, 5050, 5974, 653, 5862, 3441, 4088, 1684, 5794, 9173, 2532, 3878, 2662, 2900, 6755, 406, 2938, 5442, 6745, 4065, 2608, 1771, 6267, 634, 7711, 3644, 3269, 7541, 5728, 5000, 3728, 3652, 387, 3164, 6528, 5378, 4564, 1137, 4573, 5753, 8346, 6548, 5425, 452, 1889, 4279, 2925, 9512, 4349, 626, 1776, 9774, 7119, 5663, 5139, 7149, 9932, 8379, 1894, 6311, 9446, 3114, 4173, 727, 7144, 27, 8518, 8821, 3228, 5967, 7066, 1146, 5409, 5143, 2041, 4920, 8308, 5067, 6691, 5344, 6592, 4844, 9083, 2085, 3143, 6888, 6211, 2851, 9324, 4930, 6653, 8977, 6, 4978, 4700, 3443, 7043, 9502, 9939, 5279, 7618, 7238, 7244, 3501, 8375, 7752, 2780, 1389, 4649, 8445, 5491, 1530, 3848, 5085, 3680, 3262, 2414, 400, 757, 4011, 7784, 10015, 1193, 7461, 6790, 9431, 3185, 6291, 8099, 6547, 3997, 2417, 90, 1746, 6965, 3585, 2881, 8486, 7611, 822, 9132, 4082, 1988, 7478, 2184, 7612, 8702, 9157, 9755, 5198, 7251, 10037, 8270, 6991, 8976, 7305, 2607, 7777, 7373, 4246, 4050, 4543, 8540, 7939, 3919, 4499, 7206, 1269, 4681, 3841, 4451, 5502, 5238, 8849, 1320, 2267, 2471, 3788, 6275, 2503, 3505, 1052, 6797, 6678, 5421, 8890, 7633, 6812, 1020, 3388, 6883, 6381, 9569, 320, 9432, 6232, 7814, 96, 5763, 4892, 6389, 6865, 8818, 8947, 9883, 3613, 7999, 3595, 4471, 7140, 475, 6371, 5507, 6624, 2704, 7657, 2091, 441, 6455, 9697, 9246, 444, 1375, 7022, 2223, 7564, 2977, 823, 4262, 5363, 3467, 7449, 5355, 5529, 4558, 6906, 4133, 1341, 7705, 317, 853, 5733, 3673, 1124, 659, 508, 4051, 3266, 333, 2496, 3908, 2068, 7758, 1874, 9240, 3571, 7619, 4198, 6043, 2749, 9926, 9949, 2683, 5096, 9481, 420, 5111, 9433, 6149, 6498, 3249, 1245, 9700, 3978, 1669, 4941, 9837, 1983, 9272, 672, 5688, 8728, 7018, 6071, 1129, 8289, 5590, 207, 6882, 8031, 1729, 7102, 5934, 7532, 2506, 7135, 2885, 8548, 4425, 8817, 7921, 7616, 7136, 9707, 4397, 5280, 4022, 1419, 4569, 7385, 3995, 7613, 9336, 9999, 5511, 470, 8098, 5325, 2979, 7988, 3475, 5813, 4232, 5576, 4581, 9767, 4526, 9106, 166, 8464, 3130, 1402, 3954, 9096, 3937, 7800, 8041, 7342, 282, 1524, 4820, 3630, 6625, 3986, 5016, 9528, 6046, 7753, 9068, 8698, 5632, 6971, 9017, 5419, 5764, 7434, 4438, 5023, 4118, 3777, 1976, 3155, 5169, 1958, 8779, 3033, 3138, 3545, 7933, 4530, 9659, 8595, 9777, 4636, 1647, 3180, 4853, 3727, 5912, 2939, 4952, 231, 2073, 4494, 745, 893, 9066, 4786, 8042, 1680, 200, 9405, 4658, 7690, 7843, 7216, 5582, 3020, 841, 4136, 7827, 1869, 1070, 6565, 8056, 1213, 9453, 878, 2485, 2444, 9221, 1395, 4066, 1940, 9143, 6818, 9933, 9766, 3697, 8561, 7381, 7253, 4871, 9642, 7025, 5003, 9316, 986, 9988, 1625, 3404, 3457, 4335, 1330, 2573, 3929, 2847, 9043, 1229, 2564, 43, 6693, 9729, 7699, 4771, 534, 3792, 4720, 4632, 7438, 1166, 3824, 4334, 9663, 3241, 1880, 8922, 3683, 2441, 4352, 2330, 977, 2718, 5039, 9325, 4728, 7195, 2037, 7679, 4982, 6594, 4460, 8199, 8847, 8090, 7172, 1317, 9798, 7078, 4102, 423, 1496, 9424, 9619, 339, 4415, 9441, 2870, 7708, 8502, 7245, 2973, 9590, 7141, 1494, 7700, 5700, 6690, 5460, 5260, 1713, 2634, 5403, 6744, 8117, 4722, 6561, 9012, 601, 7451, 1442, 5153, 4135, 5296, 1899, 6622, 8431, 18, 8889, 7569, 6770, 888, 3073, 8494, 5927, 8167, 7242, 845, 4375, 8998, 2146, 4719, 7178, 7941, 1989, 472, 9975, 3920, 2594, 5091, 9024, 224, 9048, 6684, 1527, 1858, 7560, 1924, 2522, 8165, 4781, 8337, 4479, 6807, 7905, 7736, 3993, 7483, 9031, 2369, 6284, 3122, 9820, 8327, 2236, 1143, 6798, 5568, 8318, 4377, 42, 4634, 4891, 9616, 9501, 8022, 2434, 7316, 8824, 7935, 5654, 5446, 9042, 8903, 6180, 7460, 5272, 3090, 3912, 9368, 6274, 3826, 6730, 715, 5213, 6246, 6325, 2492, 8115, 606, 8229, 9669, 5439, 1644, 7213, 1633, 8617, 7486, 251, 2361, 6717, 2529, 1225, 7692, 5546, 6512, 1315, 5383, 8742, 6226, 5188, 7994, 8864]\n"]}]},{"cell_type":"markdown","source":["Calling functions from above to begin creating of the train set."],"metadata":{"id":"M71OpDC5eXtI"}},{"cell_type":"code","source":["# loading paths to images and voxel models\n","i_paths, v_paths = load_paths_from_json()\n","\n","# selecting only 1000 random samples\n","i_paths = [i_paths[i] for i in indx]\n","v_paths = [v_paths[i] for i in indx]\n","\n","arrays = []\n","voxels = []\n","\n","for i, v in zip(i_paths, v_paths):\n","    result = load_img_voxel(i,v)\n","    if result is not None:\n","        array, voxel = result\n","    #array, voxel = load_img_voxel(i,v)\n","\n","    arrays.append(array)\n","    voxels.append(voxel)\n","\n","# printing final size of arrays loaded to check everything went OK, if both\n","# are 1000, load probably went OK\n","print(len(arrays))\n","print(len(voxels))\n","\n","# making arrays from the lists\n","images = np.stack(arrays, axis=0)\n","voxels = np.stack(voxels, axis=0).reshape((1000,32,32,32))\n","\n","# this can save loaded images and voxels as arrays to Google drive, so it is done for next run\n","#save_path = '/content/drive/MyDrive/' + rest of the path in your drive\n","#np.save(save_path + 'imgs_as_arrays.npy', np.stack(arrays, axis=0))\n","#np.save(save_path + 'voxels_as_arrays.npy', np.stack(voxels, axis=0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"huM57Lt0CPao","executionInfo":{"status":"ok","timestamp":1715870677862,"user_tz":-120,"elapsed":72202,"user":{"displayName":"Matyáš Pokorný","userId":"06975905606393697570"}},"outputId":"a7f1a0a7-37f6-4f79-f202-e0fa4a26b796"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n","1000\n"]}]},{"cell_type":"markdown","source":["Now we have our train set ready for a single-view reconstruction test."],"metadata":{"id":"AaSa4yy3jpxi"}},{"cell_type":"markdown","source":["Now we'll import additional libraries for model training/testing."],"metadata":{"id":"mDJgljC3kGr2"}},{"cell_type":"code","source":["import numpy as np\n","from matplotlib import pyplot as plt\n","import random\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.metrics import MeanAbsoluteError, RootMeanSquaredError, MeanSquaredError\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, losses\n","from tensorflow.keras.models import Model\n","\n","from datetime import datetime\n","import pytz\n","\n","import os"],"metadata":{"id":"UGI02mgN3WZp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Spliting the dataset into train, test and validation parts. The train set has 80% of the data and test and validation sets both have 10% of the dataset.\n","\n","Splitting dataset like is common in machine learning and proven effective.\n","\n","The random_state argument is for having the same random seed every time, so the dataset is split randomly, but the same each time it is run. It can be any positive integer."],"metadata":{"id":"iVbwFB1431W2"}},{"cell_type":"code","source":["X_train, X_rem, y_train, y_rem = train_test_split(images,voxels, train_size=0.8, random_state=42)\n","X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state=42)\n","\n","del images, voxels, X_rem, y_rem\n","\n","print(np.shape(X_train))\n","print(np.shape(y_train))\n","print(np.shape(X_valid))\n","print(np.shape(y_valid))\n","print(np.shape(X_test))\n","print(np.shape(y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5UmdBvh_3a3q","executionInfo":{"status":"ok","timestamp":1715871508653,"user_tz":-120,"elapsed":1059,"user":{"displayName":"Matyáš Pokorný","userId":"06975905606393697570"}},"outputId":"98c597af-07d1-46f2-ada3-27914efae6f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(800, 256, 256, 3)\n","(800, 32, 32, 32)\n","(100, 256, 256, 3)\n","(100, 32, 32, 32)\n","(100, 256, 256, 3)\n","(100, 32, 32, 32)\n"]}]},{"cell_type":"markdown","source":["Crucial part of defining our model's architecture into model variable. This is model 3, with work name 2404131212."],"metadata":{"id":"WSpvBFBQ5h_L"}},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","        layers.Input(shape = (256, 256, 3)),\n","        layers.Conv2D(32, kernel_size=15, padding='same',strides=1, activation='relu'),\n","        layers.Conv2D(32, kernel_size=9, padding='same',strides=1, activation='relu'),\n","        layers.MaxPool2D(2),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(64, kernel_size=7, padding='same',strides=1, activation='relu'),\n","        layers.Conv2D(64, kernel_size=7, padding='same', strides=1, activation='relu'),\n","        layers.MaxPool2D(2),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(128, kernel_size=3, padding='same', strides=1, activation='relu'),\n","        layers.Conv2D(128, kernel_size=3, padding='same', strides=1, activation='relu'),\n","        layers.MaxPool2D(2),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(256, kernel_size=3, padding='same', strides=1, activation = 'relu'),\n","        layers.Conv2D(256, kernel_size=3, padding='same', strides=1, activation = 'sigmoid'),\n","        layers.MaxPool2D(2),\n","        layers.BatchNormalization(),\n","\n","\n","        layers.Reshape((16, 16, 1, 256)),\n","\n","        layers.Conv3DTranspose(128, kernel_size=(3,3,3), padding='same',strides=1, activation='relu'),\n","        layers.Conv3DTranspose(128, kernel_size=(3,3,3), padding='same',strides=1, activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.UpSampling3D((1,1,8)),\n","        layers.Conv3DTranspose(64, kernel_size=(5,5,5), padding='same',strides=1, activation='relu'),\n","        layers.Conv3DTranspose(64, kernel_size=(5,5,5), padding='same',strides=1, activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.UpSampling3D((2,2,4)),\n","        layers.Conv3D(1, kernel_size=1, activation='sigmoid', padding='same'),\n","        layers.Reshape((32, 32, 32))\n","\n","])\n","# Adam optimizer is used for model and BCE as both loss function and metric\n","model.compile(optimizer='adam', loss=losses.BinaryCrossentropy(), metrics='binary_crossentropy')\n","# summary function will show us what the model looks like and how the parameters are distributed,\n","# also the shape of output of each layer is showed, and the size of the model at the end\n","model.summary()"],"metadata":{"id":"dmlA34JN5eRA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now the most fun part is the training of the model.\n","\n","The following cells will:\n","\n","1) Train the model, using train and validation data, for 50 epochs, with batch size of 32, and save the information about training into history variable\n","\n","2) From the history variable we can now draw a plot of train and validation loss, to see how the model was build and if there is a need for further training or training the whole model again for less epochs.\n","\n","3) Into variable date_time, time when the training was finished will be written and\n","\n","4) the model, with weights, biases and the architecture will be saved in the memory of this session as .keras format (https://www.tensorflow.org/tutorials/keras/save_and_load)."],"metadata":{"id":"BDkrnkvm60zx"}},{"cell_type":"code","source":["history = model.fit(X_train, y_train,\n","                batch_size = 32,\n","                epochs=50,\n","                shuffle=True,\n","                validation_data=(X_valid, y_valid))"],"metadata":{"id":"oLACPcbG6lfz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['loss'][10:], label='loss')\n","plt.plot(history.history['val_loss'][10:], label='val_loss')\n","plt.show()"],"metadata":{"id":"6T0Czi186ryT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","import pytz\n","\n","CET = pytz.timezone('Europe/Prague')\n","now = datetime.now(CET)\n","date_time = now.strftime(\"%y%m%d%H%M\")\n","print(date_time)"],"metadata":{"id":"4_7vbP2k6s1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save('/content/'+date_time+'.keras')"],"metadata":{"id":"o_Du3pvl6uKp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["However, for just evaluating the model, we can load already trained model 1, by uploading it into this session and use the following cell. The summary method will show us the model was loaded as should.\n","\n","Note: the model can be saved or loaded easily from Google Drive (if the Drive is mounted to the session)"],"metadata":{"id":"amHTKdAF6j6r"}},{"cell_type":"code","source":["model = tf.keras.models.load_model('/content/2404131212.keras')\n","model.summary()"],"metadata":{"id":"-t7QUjpF6YN-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's evaluate the model."],"metadata":{"id":"FTiZTD079bB9"}},{"cell_type":"markdown","source":["First there are defined the metrics that will show us the performance of the model."],"metadata":{"id":"f_lpUxxk9fk7"}},{"cell_type":"code","source":["def MAE(X, y):\n","  mae = tf.keras.metrics.MeanAbsoluteError()\n","  mae.update_state([X], [y])\n","  mae.result().numpy()\n","  print('MAE = ', mae.result().numpy())\n","  return mae.result().numpy()\n","\n","def STD(X, y):\n","  difference = np.subtract(X, y)\n","  std = np.round(np.std(difference),10)\n","  print('STD = ',std)\n","  return std\n","\n","def BCE(X, y):\n","  bce = tf.keras.metrics.BinaryCrossentropy()\n","  bce.update_state([X], [y])\n","  bce.result().numpy()\n","  print('BCE = ', bce.result().numpy())\n","  return bce.result().numpy()\n"],"metadata":{"id":"t6nF1xXc9YN0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There, the model test data will be put into the model, which will predict (with predict() method) the voxels, which are 16-bit floats between 0 and 1.\n","\n","Then the threshold is applied to convert the float data into 8-bit integer voxels."],"metadata":{"id":"YSVmwa-f9vDQ"}},{"cell_type":"code","source":["test_pred = model.predict(X_test)\n","test_pred_tresholded = np.where(test_pred >0.5, 1, 0)\n","del test_pred\n","test_pred_tresholded = test_pred_tresholded.astype('uint8')"],"metadata":{"id":"YC6kBuZD9tDk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There we use the functions for metrics we defined earlier to numerize the model performance. The thresholded predicted voxels and the ground thruth voxels from test set are used for evaluation. Again, the test set was not seen by model during training and so it is an independent control."],"metadata":{"id":"HhgKpOEB_TW1"}},{"cell_type":"code","source":["MAE(test_pred_tresholded, y_test)\n","STD(test_pred_tresholded, y_test)\n","BCE(test_pred_tresholded, y_test)"],"metadata":{"id":"tCYQLLsX_QnQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And finally, the qualitative evaluation of the model with graphical display.\n","\n","In the top row there are test images, in the middle row the voxels predicted by the model, and in the bottom row there are corresponding ground thruth voxels fro the comparison.\n","\n","More from the test set can be seen by changing the k parameter at top to other positive integer and simply running the cell again."],"metadata":{"id":"KR8IubG2_6Fc"}},{"cell_type":"code","source":["# Change this variable to any positive integer to look through the test set\n","k = 0\n","\n","n = 4\n","m = k*n\n","fig =  plt.figure(figsize=(20, 20))\n","for i in range(n):\n","    ax = fig.add_subplot(3, 4, i + 1)\n","    plt.imshow(X_test[i+m])\n","\n","    ax = fig.add_subplot(3, 4, i + n + 1, projection='3d')\n","    ax.voxels(test_pred_tresholded[i+m,:,:,:], edgecolor='k')\n","\n","    ax = fig.add_subplot(3, 4, i + n + n + 1, projection='3d')\n","    ax.voxels(y_test[i+m,:,:,:], edgecolor='k')\n","plt.show()"],"metadata":{"id":"5U4WRhDH_2YR"},"execution_count":null,"outputs":[]}]}